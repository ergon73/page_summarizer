"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞.
"""

import sys
from agent import PageSummarizer

def test_url_validation():
    """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ URL."""
    agent = PageSummarizer()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ URL
    valid_urls = [
        "https://example.com",
        "http://test.org",
        "https://www.google.com"
    ]
    
    for url in valid_urls:
        assert agent._validate_url(url), f"URL {url} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ URL
    invalid_urls = [
        "not_a_url",
        "ftp://example.com",  # –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª
        "",
        "just_text"
    ]
    
    for url in invalid_urls:
        assert not agent._validate_url(url), f"URL {url} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º"
    
    print("‚úÖ –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ URL –ø—Ä–æ–π–¥–µ–Ω")

def test_text_cleaning():
    """–¢–µ—Å—Ç –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞."""
    agent = PageSummarizer()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å –ª–∏—à–Ω–∏–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏ —Å–∏–º–≤–æ–ª–∞–º–∏
    dirty_text = """
    –≠—Ç–æ    —Ç–µ—Å—Ç   —Ç–µ–∫—Å—Ç–∞.
    
    
    –° –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏     –ø—Ä–æ–±–µ–ª–∞–º–∏!!!
    –ò —Å—Ç—Ä–∞–Ω–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ @@@ ### $$$.
    """
    
    clean_text = agent._clean_text(dirty_text)
    
    # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {repr(dirty_text)}")
    print(f"–û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {repr(clean_text)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã —É–¥–∞–ª–µ–Ω—ã (–¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª)
    if "  " in clean_text:
        print(f"–û–®–ò–ë–ö–ê: –ù–∞–π–¥–µ–Ω—ã –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤ –ø–æ–∑–∏—Ü–∏—è—Ö: {[i for i, c in enumerate(clean_text) if clean_text[i:i+2] == '  ']}")
    assert "  " not in clean_text, "–î–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã"
    assert "!!!" not in clean_text, "–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã"
    assert "@@@" not in clean_text, "–°—Ç—Ä–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–∂–∏–¥–∞–µ–º—ã–µ —Å–ª–æ–≤–∞
    assert "–≠—Ç–æ —Ç–µ—Å—Ç —Ç–µ–∫—Å—Ç–∞" in clean_text, "–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å—Å—è"
    
    print("‚úÖ –¢–µ—Å—Ç –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–π–¥–µ–Ω")

def test_html_extraction():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML."""
    agent = PageSummarizer()
    
    # –ü—Ä–æ—Å—Ç–æ–π HTML –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_html = """
    <html>
    <head><title>–¢–µ—Å—Ç</title></head>
    <body>
        <nav>–ù–∞–≤–∏–≥–∞—Ü–∏—è (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞)</nav>
        <main>
            <h1>–ì–ª–∞–≤–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫</h1>
            <p>–≠—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏. –û–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω.</p>
            <p>–í—Ç–æ—Ä–æ–π –∞–±–∑–∞—Ü —Å –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.</p>
        </main>
        <footer>–ü–æ–¥–≤–∞–ª (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–¥–∞–ª–µ–Ω)</footer>
        <script>console.log('—Å–∫—Ä–∏–ø—Ç');</script>
    </body>
    </html>
    """
    
    try:
        extracted_text = agent._extract_text(test_html)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑–≤–ª–µ—á–µ–Ω
        assert "–ì–ª–∞–≤–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫" in extracted_text, "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω"
        assert "–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏" in extracted_text, "–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω"
        assert "–≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π" in extracted_text, "–í—Ç–æ—Ä–æ–π –∞–±–∑–∞—Ü –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ–Ω—É–∂–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —É–¥–∞–ª–µ–Ω
        assert "–ù–∞–≤–∏–≥–∞—Ü–∏—è" not in extracted_text, "–ù–∞–≤–∏–≥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞"
        assert "–ü–æ–¥–≤–∞–ª" not in extracted_text, "–ü–æ–¥–≤–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–¥–∞–ª–µ–Ω"
        assert "console.log" not in extracted_text, "–°–∫—Ä–∏–ø—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–¥–∞–ª–µ–Ω—ã"
        
        print("‚úÖ –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è HTML –ø—Ä–æ–π–¥–µ–Ω")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è HTML: {e}")
        return False
    
    return True

def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤."""
    print("üß™ –ó–ê–ü–£–°–ö –¢–ï–°–¢–û–í –ê–ì–ï–ù–¢–ê")
    print("=" * 40)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ –±–µ–∑ API –∫–ª—é—á–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        print("–¢–µ—Å—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å...")
        
        test_url_validation()
        test_text_cleaning()
        test_html_extraction()
        
        print("\nüéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("=" * 40)
        print("–ê–≥–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
        print("–î–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–±–∞–≤—å—Ç–µ API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª.")
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê –í –¢–ï–°–¢–ê–•: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()